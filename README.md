# Persian NLP Django Service (Beta)

**نسخه بتا** – تمامی حقوق برای `rakhshai` محفوظ است.

این پروژه یک سرویس ساده برای تحلیل متون فارسی است که با استفاده از
**Django** و **Django REST Framework** پیاده‌سازی شده است. برای پردازش متن از
کتابخانه‌ی **Hazm** جهت نرمال‌سازی و از مدل‌های **ParsBERT** جهت تحلیل
احساس و تشخیص موجودیت‌های نامدار استفاده شده است. همچنین امکان
پردازش فایل‌های بزرگ به‌صورت غیـرهـمگام با **Celery** و **Redis** فراهم
شده است.

## ویژگی‌ها

* نرمال‌سازی متن فارسی با [Hazm](https://pypi.org/project/hazm/).
* تحلیل احساس با مدل `HooshvareLab/bert-fa-base-uncased-sentiment-snappfood`.
* تشخیص موجودیت‌های نامدار (NER) با مدل `HooshvareLab/bert-base-parsbert-ner-uncased`.
* استفاده‌ی ساده از مدل‌ها با [Transformers pipeline](https://huggingface.co/docs/transformers/en/main_classes/pipelines).
* پردازش فایل‌های متنی بزرگ در پس‌زمینه با Celery و Redis.

* پاسخ‌گویی به پرسش‌های تاریخی: علاوه بر تحلیل متن، این سرویس یک
  **پایگاه سوال و جواب** دربارهٔ تاریخ ایران باستان دارد. برای سوالات
  شناخته‌شده، پاسخ از یک فایل داخلی بازیابی می‌شود و در صورت نبود
  پاسخ، سرویس با استفاده از کتابخانه‌های استاندارد مانند
  [`wikipedia`](https://pypi.org/project/wikipedia/) خلاصه‌ای از مقاله‌های
  ویکی‌پدیای فارسی را برمی‌گرداند (نیازمند دسترسی اینترنت). این قابلیت
  روی مدل‌های آماده مانند **ParsBERT** و **Hazm** تکیه دارد تا سوال را
  نرمال‌سازی و مشابه‌ترین پرسش را بیابد.

## راه‌اندازی

این راهنما فرض می‌کند که شما Python 3.10 یا بالاتر و `pip` را نصب کرده‌اید.

1. محیط مجازی بسازید و فعال کنید:

    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```

2. وابستگی‌ها را نصب کنید:

    ```bash
    pip install django djangorestframework transformers torch hazm celery redis
    # کتابخانه‌های زیر برای پرسش و پاسخ و جستجوی اینترنتی لازم هستند
    pip install wikipedia requests
    ```

3. مخزن را کلون یا کپی کنید و وارد پوشه‌ی پروژه شوید:

    ```bash
    cd persian_nlp_project
    ```

4. مهاجرت‌های پایگاه داده را اعمال کنید و سرور توسعه را اجرا کنید:

    ```bash
    python manage.py migrate
    python manage.py runserver
    ```

5. (اختیاری) اگر قصد دارید فایل‌های بزرگ را به‌صورت غیـرهـمگام پردازش کنید، باید
   Redis را نصب و یک worker Celery اجرا کنید. نمونه‌ی ساده:

    ```bash
    # ترمینال اول
    redis-server

    # ترمینال دوم
    python manage.py migrate
    python manage.py runserver

    # ترمینال سوم
    celery -A mysite worker -l INFO
    ```

## استفاده

### تحلیل متن کوتاه

برای ارسال یک متن کوتاه و دریافت نتیجه‌ی آنی، درخواست POST به مسیر
/api/analyze/ به‌صورت زیر ارسال کنید. به‌عنوان مثال در اینجا
متنی دربارهٔ تاریخ ایران ارسال می‌شود:

```bash
curl -X POST http://127.0.0.1:8000/api/analyze/ \
  -H "Content-Type: application/json" \
  -d '{"text":"کوروش بزرگ بنیان‌گذار امپراتوری هخامنشی بود."}'
```

پاسخ نمونه:

```json
{
  "ok": true,
  "result": {
    "normalized": "کوروش بزرگ بنیان‌گذار امپراتوری هخامنشی بود.",
    "sentiment": {"label": "NEUTRAL", "score": 0.85},
    "entities": [
      {"text": "کوروش بزرگ", "label": "PER", "score": 0.96, "start": 0, "end": 11},
      {"text": "امپراتوری هخامنشی", "label": "ORG", "score": 0.93, "start": 24, "end": 42}
    ]
  }
}

```

### پردازش فایل بزرگ

برای پردازش فایل متنی بزرگ، آن را به‌صورت multipart ارسال کنید. در این
حالت Celery یک job پس‌زمینه ایجاد می‌کند و شناسه‌ی آن را برمی‌گرداند:

```bash
curl -F "file=@/path/to/comments.txt" http://127.0.0.1:8000/api/analyze/
```

خروجی اولیه:

```json
{"ok": true, "job_id": "<celery id>"}
```

برای بررسی وضعیت job:

```bash
curl http://127.0.0.1:8000/api/jobs/<celery id>/
```

اگر job تمام شده باشد، مسیر فایل خروجی و تعداد خطوط پردازش شده برگردانده
می‌شود.

### پرسش و پاسخ دربارهٔ تاریخ ایران باستان

برای طرح یک پرسش تاریخی (مثلاً دربارهٔ کوروش یا هخامنشیان) از مسیر
`/api/answer/` استفاده کنید. بدنهٔ درخواست باید شامل فیلد
`question` (رشتهٔ فارسی) باشد. نمونه:

```bash
curl -X POST http://127.0.0.1:8000/api/answer/ \
  -H "Content-Type: application/json" \
  -d '{"question":"امپراتوری هخامنشی چه زمانی تشکیل شد؟"}'
```

خروجی نمونه:

```json
{
  "ok": true,
  "answer": "امپراتوری هخامنشی در سال ۵۵۰ پیش از میلاد به‌وسیلهٔ کوروش بزرگ تأسیس شد و در سال ۳۳۰ پیش از میلاد با فتح توسط اسکندر مقدونی به پایان رسید."
}
```

این نقطهٔ پایانی صرفاً یک مثال از سوالات موجود در فایل `qa_data.json` است.
اگر سوال شما در این فایل یافت نشود، سرویس با استفاده از کتابخانهٔ
`wikipedia` خلاصه‌ای از مقالهٔ مرتبط در ویکی‌پدیای فارسی را جستجو
می‌کند و به‌عنوان پاسخ باز می‌گرداند. بنابراین لازم است ماشین میزبان
دسترسی به اینترنت داشته باشد تا این بخش به‌درستی عمل کند.

#### افزودن یا ویرایش سوالات

سوال و جواب‌های داخلی در فایل `nlp/qa_data.json` ذخیره شده‌اند. هر
ورودی شامل دو کلید `question` و `answer` است. در صورت نیاز می‌توانید
این فایل را ویرایش و سوالات جدید اضافه کنید. پس از ویرایش، سرور
باید مجدداً راه‌اندازی شود تا تغییرات بارگذاری شوند.

## تغییر مدل یا وظیفه

اگر تمایل دارید نوع تحلیل را عوض کنید (مثلاً خلاصه‌سازی یا طبقه‌بندی
موضوعی)، کافی است مدل مربوطه را در فایل `nlp/pipelines.py` جایگزین کنید.
کتابخانه‌ی Transformers پشتیبانی از وظایف مختلف را ارائه می‌دهد.

## توجه حقوقی

این پروژه تحت نسخه‌ی بتا ارائه می‌شود و **تمام حقوق مادی و معنوی متعلق به
`rakhshai`** می‌باشد. استفاده از این پروژه تنها برای اهداف آموزشی و
تحقیقاتی مجاز است.
